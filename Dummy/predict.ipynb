{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import sqlite3\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ai16/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '/data/SO_predict_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/SO_predict_DATA/train.db'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc+'/train.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(loc+'/train.db'):\n",
    "    start = datetime.now()\n",
    "    disk_engine = create_engine('sqlite:///train.db')\n",
    "    #start = dt.datetime.now()\n",
    "    chunksize = 180000\n",
    "    j = 0\n",
    "    index_start = 1\n",
    "    for df in pd.read_csv(loc+'/Train.csv', names=['Id', 'Title', 'Body', 'Tags'], chunksize=chunksize, iterator=True, encoding='utf-8', ):\n",
    "        df.index += index_start\n",
    "        j+=1\n",
    "        print('{} rows'.format(j*chunksize))\n",
    "        df.to_sql('data', disk_engine, if_exists='append')\n",
    "        index_start = df.index[-1] + 1\n",
    "    print(\"Time taken :\", datetime.now() - start)\n",
    "else:\n",
    "    print(\"Already Exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the database : \n",
      " 6034196\n",
      "Time taken to count the number of rows : 0:00:00.129280\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(loc+'/train.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect(loc+'/train.db')\n",
    "    num_rows = pd.read_sql_query(\"\"\"SELECT count(*) FROM data\"\"\", con)\n",
    "    print(\"Number of rows in the database :\",\"\\n\",num_rows['count(*)'].values[0])\n",
    "    con.close()\n",
    "    print(\"Time taken to count the number of rows :\", datetime.now() - start)\n",
    "else:\n",
    "    print(\"Error !! DB file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:22.584121\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(loc+'/train.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect(loc+'/train.db')\n",
    "    df_no_dup = pd.read_sql_query('SELECT Title, Body, Tags, COUNT(*) as cnt_dup FROM data GROUP BY Title, Body, Tags', con)\n",
    "    con.close()\n",
    "    print(\"Time taken to run this cell :\", datetime.now() - start)\n",
    "else:\n",
    "    print(\"Error !! DB file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate questions : 1827881 ( 30.292038906260256 % )\n"
     ]
    }
   ],
   "source": [
    "print(\"number of duplicate questions :\", num_rows['count(*)'].values[0]- df_no_dup.shape[0], \"(\",(1-((df_no_dup.shape[0])/(num_rows['count(*)'].values[0])))*100,\"% )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2656284\n",
       "2    1272336\n",
       "3     277575\n",
       "4         90\n",
       "5         25\n",
       "6          5\n",
       "Name: cnt_dup, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup.cnt_dup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_no_dup.cnt_dup[df_no_dup.Tags.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new database with no duplicates\n",
    "if not os.path.isfile(loc+'/train_no_dup.db'):\n",
    "    disk_dup = create_engine(\"sqlite:///train_no_dup.db\")\n",
    "    no_dup = pd.DataFrame(df_no_dup, columns=['Title', 'Body', 'Tags'])\n",
    "    no_dup.to_sql('no_dup_train',disk_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Tags\n",
      "0                                c++ c\n",
      "1          c# silverlight data-binding\n",
      "2  c# silverlight data-binding columns\n",
      "3                             jsp jstl\n",
      "4                            java jdbc\n",
      "Time taken : 0:00:09.445131\n"
     ]
    }
   ],
   "source": [
    "#This method seems more appropriate to work with this much data.\n",
    "#creating the connection with database file.\n",
    "if os.path.isfile(loc+'/train_no_dup.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect(loc+'/train_no_dup.db')\n",
    "    tag_data = pd.read_sql_query(\"\"\"SELECT Tags FROM no_dup_train\"\"\", con)\n",
    "    #Always remember to close the database\n",
    "    con.close()\n",
    "\n",
    "    # Let's now drop unwanted column.\n",
    "    #tag_data.drop(tag_data.index[0], inplace=True)\n",
    "    #Printing first 5 columns from our data frame\n",
    "    print(tag_data.head())\n",
    "    print(\"Time taken :\", datetime.now() - start)\n",
    "else:\n",
    "    print(\"Error !! DB file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Entries with no Tags\n",
    "\n",
    "len(tag_data[tag_data['Tags'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4206315, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete rows with tag is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7f0c19100cc0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_engine = create_engine('sqlite:///train_no_dup.db')\n",
    "disk_engine.execute(\"\"\"DELETE FROM no_dup_train WHERE Tags IS NULL\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Time taken :', datetime.timedelta(0, 10, 509544))\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(loc+'/train_no_dup.db'):\n",
    "    start = datetime.now()\n",
    "    con = sqlite3.connect(loc+'/train_no_dup.db')\n",
    "    \n",
    "    #con.close()\n",
    "    tag_data = pd.read_sql_query(\"\"\"SELECT Tags FROM no_dup_train\"\"\", con)\n",
    "    con.close()\n",
    "    #Always remember to close the database\n",
    "    con.close()\n",
    "    print(\"Time taken :\", datetime.now() - start)\n",
    "else:\n",
    "    print(\"Error !! DB file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_data[tag_data['Tags'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4206308, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by default 'split()' will tokenize each tag using space\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "tag_dtm = vectorizer.fit_transform(tag_data['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of data points :', 4206308)\n",
      "('Number of unique tags :', 42048)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points :\", tag_dtm.shape[0])\n",
    "print(\"Number of unique tags :\", tag_dtm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Some of the tags we have :', [u'.a', u'.app', u'.asp.net-mvc', u'.aspxauth', u'.bash-profile', u'.class-file', u'.cs-file', u'.doc', u'.drv', u'.ds-store'])\n"
     ]
    }
   ],
   "source": [
    "#'get_feature_name()' gives us the vocabulary.\n",
    "tags = vectorizer.get_feature_names()\n",
    "#Lets look at the tags we have.\n",
    "print(\"Some of the tags we have :\", tags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/15115765/how-to-access-sparse-matrix-elements\n",
    "#Lets now store the document term matrix in a dictionary.\n",
    "freqs = tag_dtm.sum(axis=0).A1\n",
    "result = dict(zip(tags, freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdbg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fouc</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdraid</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>screen-resolution</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mms-streaming</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tags  Counts\n",
       "0               mdbg      14\n",
       "1               fouc      23\n",
       "2             mdraid       4\n",
       "3  screen-resolution     477\n",
       "4      mms-streaming      10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving this dictionary to csv files.\n",
    "if not os.path.isfile('tag_counts_dict_dtm.csv'):\n",
    "    with open('tag_counts_dict_dtm.csv', 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Tags', 'Counts'])\n",
    "        for key, value in result.items():\n",
    "            writer.writerow([key, value])\n",
    "            \n",
    "tag_df = pd.read_csv(\"tag_counts_dict_dtm.csv\")\n",
    "tag_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n",
      "QuestionsProcessed\n"
     ]
    }
   ],
   "source": [
    "#http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(loc+db_file)\n",
    "        return conn\n",
    "    except sqlite3.Error as er:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def checkTableExists(dbcon):\n",
    "    cursr = dbcon.cursor()\n",
    "    str = \"select name from sqlite_master where type='table'\"\n",
    "    table_names = cursr.execute(str)\n",
    "    print(\"Tables in the databse:\")\n",
    "    tables =table_names.fetchall() \n",
    "    print(tables[0][0])\n",
    "    return(len(tables))\n",
    "\n",
    "def create_database_table(database, query):\n",
    "    conn = create_connection(database)\n",
    "    if conn is not None:\n",
    "        create_table(conn, query)\n",
    "        checkTableExists(conn)\n",
    "    else:\n",
    "        print(\"Error! cannot create the database connection.\")\n",
    "    conn.close()\n",
    "\n",
    "sql_create_table = \"\"\"CREATE TABLE IF NOT EXISTS QuestionsProcessed (question text NOT NULL, code text, tags text, words_pre integer, words_post integer, is_code integer);\"\"\"\n",
    "create_database_table(\"Processed.db\", sql_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n",
      "no_dup_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dup_con = create_connection('/train_no_dup.db')\n",
    "checkTableExists(no_dup_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "if no_dup_con  is not None:\n",
    "    temp_d = pd.read_sql_query(\"\"\"SELECT * FROM no_dup_train LIMIT 1,3\"\"\", no_dup_con)\n",
    "    print(type(temp_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'Title', u'Body', u'Tags'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"<p>I should do binding for datagrid dynamically at code. I wrote the code as below. When I debug this code block, it seems that it does bindings correctly, but grid comes with no columns on form.</p>\\n\\n<pre><code>MyClass myInstance = new MyClass();\\ndataGridObject = new DataGrid();\\ndataGridObject.Width = 200;\\ndataGridObject.Height = 200;\\nbinding = new Binding();\\nbinding.Source = myInstance;\\nforeach (PropertyInfo prop in myInstance.GetType().GetProperties())\\n{\\n    binding.Path = new PropertyPath(prop.Name);\\n    DataGridTextColumn column = new DataGridTextColumn();\\n    column.Header = prop.Name;\\n    column.Binding = new Binding(prop.Name);\\n    dataGridObject.Columns.Add(column);\\n}\\n\\ndataGridObject.ItemSource = myInstanceList;\\n</code></pre>\\n\\n<p>Why doesn't come grid with columns, although I did necessary bindings?\\nThanks for the replies in advance..</p>\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_bo = temp_d.iloc[0]['Body']\n",
    "t_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>I should do binding for datagrid dynamically at code. I wrote the code as below. When I debug this code block, it seems that it does bindings correctly, but grid comes with no columns on form.</p>\n",
      "\n",
      "<pre><code>MyClass myInstance = new MyClass();\n",
      "dataGridObject = new DataGrid();\n",
      "dataGridObject.Width = 200;\n",
      "dataGridObject.Height = 200;\n",
      "binding = new Binding();\n",
      "binding.Source = myInstance;\n",
      "foreach (PropertyInfo prop in myInstance.GetType().GetProperties())\n",
      "{\n",
      "    binding.Path = new PropertyPath(prop.Name);\n",
      "    DataGridTextColumn column = new DataGridTextColumn();\n",
      "    column.Header = prop.Name;\n",
      "    column.Binding = new Binding(prop.Name);\n",
      "    dataGridObject.Columns.Add(column);\n",
      "}\n",
      "\n",
      "dataGridObject.ItemSource = myInstanceList;\n",
      "</code></pre>\n",
      "\n",
      "<p>Why doesn't come grid with columns, although I did necessary bindings?\n",
      "Thanks for the replies in advance..</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def striphtml(data):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(data))\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I should do binding for datagrid dynamically at code. I wrote the code as below. When I debug this code block, it seems that it does bindings correctly, but grid comes with no columns on form. \\n\\n  MyClass myInstance = new MyClass();\\ndataGridObject = new DataGrid();\\ndataGridObject.Width = 200;\\ndataGridObject.Height = 200;\\nbinding = new Binding();\\nbinding.Source = myInstance;\\nforeach (PropertyInfo prop in myInstance.GetType().GetProperties())\\n{\\n    binding.Path = new PropertyPath(prop.Name);\\n    DataGridTextColumn column = new DataGridTextColumn();\\n    column.Header = prop.Name;\\n    column.Binding = new Binding(prop.Name);\\n    dataGridObject.Columns.Add(column);\\n}\\n\\ndataGridObject.ItemSource = myInstanceList;\\n  \\n\\n Why doesn't come grid with columns, although I did necessary bindings?\\nThanks for the replies in advance.. \\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = striphtml(t_bo)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u\"you're\",\n",
       " u\"you've\",\n",
       " u\"you'll\",\n",
       " u\"you'd\",\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u\"she's\",\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u\"it's\",\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u\"that'll\",\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u\"don't\",\n",
       " u'should',\n",
       " u\"should've\",\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u\"aren't\",\n",
       " u'couldn',\n",
       " u\"couldn't\",\n",
       " u'didn',\n",
       " u\"didn't\",\n",
       " u'doesn',\n",
       " u\"doesn't\",\n",
       " u'hadn',\n",
       " u\"hadn't\",\n",
       " u'hasn',\n",
       " u\"hasn't\",\n",
       " u'haven',\n",
       " u\"haven't\",\n",
       " u'isn',\n",
       " u\"isn't\",\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u\"mightn't\",\n",
       " u'mustn',\n",
       " u\"mustn't\",\n",
       " u'needn',\n",
       " u\"needn't\",\n",
       " u'shan',\n",
       " u\"shan't\",\n",
       " u'shouldn',\n",
       " u\"shouldn't\",\n",
       " u'wasn',\n",
       " u\"wasn't\",\n",
       " u'weren',\n",
       " u\"weren't\",\n",
       " u'won',\n",
       " u\"won't\",\n",
       " u'wouldn',\n",
       " u\"wouldn't\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "read_db = 'train_no_dup.db'\n",
    "write_db = 'Processed.db'\n",
    "if os.path.isfile(read_db):\n",
    "    conn_r = create_connection(read_db)\n",
    "    if conn_r is not None:\n",
    "        reader =conn_r.cursor()\n",
    "        reader.execute(\"SELECT Title, Body, Tags From no_dup_train ORDER BY RANDOM() LIMIT 1000000;\")\n",
    "\n",
    "if os.path.isfile(write_db):\n",
    "    conn_w = create_connection(write_db)\n",
    "    if conn_w is not None:\n",
    "        tables = checkTableExists(conn_w)\n",
    "        writer =conn_w.cursor()\n",
    "        if tables != 0:\n",
    "            writer.execute(\"DELETE FROM QuestionsProcessed WHERE 1\")\n",
    "            print(\"Cleared All the rows\")\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'wive'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
